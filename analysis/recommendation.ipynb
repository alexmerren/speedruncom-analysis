{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Systems for Speedrun.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation by User ID using Bipartite Graph\n",
    "\n",
    "This method of recommendation works by finding other users that have played the same game as a target user. The games that the other users have played are ranked by occurrence. Games that the target user has not played but the other users have played are then recommended in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from operator import itemgetter\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prefs_filename = \"../data/users/user_preferences_with_metadata.csv\"\n",
    "user_prefs_df = pd.read_csv(user_prefs_filename)\n",
    "user_prefs_df = user_prefs_df[(user_prefs_df['signup_date'].notna()) & (user_prefs_df['signup_date'] != \"Null\")]\n",
    "user_prefs_df['signup_date'] = pd.to_datetime(user_prefs_df['signup_date'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "user_prefs_df['signup_date'] = pd.to_datetime(user_prefs_df['signup_date'].dt.strftime('%Y-%m-%d'))\n",
    "user_prefs_df = user_prefs_df[(user_prefs_df['signup_date'] < '2023-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>signup_date</th>\n",
       "      <th>location</th>\n",
       "      <th>num_games</th>\n",
       "      <th>games</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>335322</td>\n",
       "      <td>335322</td>\n",
       "      <td>335322</td>\n",
       "      <td>335322.000000</td>\n",
       "      <td>335322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>335322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>j5wzz2qj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>k6q4rqzd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-28 13:40:53.271780608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.994465</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-01-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-09-16 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-25 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2059.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.410692</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user                    signup_date location      num_games  \\\n",
       "count     335322                         335322   335322  335322.000000   \n",
       "unique    335322                            NaN      257            NaN   \n",
       "top     j5wzz2qj                            NaN       us            NaN   \n",
       "freq           1                            NaN   101439            NaN   \n",
       "mean         NaN  2020-06-28 13:40:53.271780608      NaN       1.994465   \n",
       "min          NaN            2014-01-06 00:00:00      NaN       1.000000   \n",
       "25%          NaN            2019-09-16 00:00:00      NaN       1.000000   \n",
       "50%          NaN            2021-01-04 00:00:00      NaN       1.000000   \n",
       "75%          NaN            2021-09-25 00:00:00      NaN       2.000000   \n",
       "max          NaN            2022-12-31 00:00:00      NaN    2059.000000   \n",
       "std          NaN                            NaN      NaN       7.410692   \n",
       "\n",
       "           games  \n",
       "count     335322  \n",
       "unique     88806  \n",
       "top     k6q4rqzd  \n",
       "freq        5131  \n",
       "mean         NaN  \n",
       "min          NaN  \n",
       "25%          NaN  \n",
       "50%          NaN  \n",
       "75%          NaN  \n",
       "max          NaN  \n",
       "std          NaN  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prefs_df.describe(include='all', datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_games_df = user_prefs_df.copy()\n",
    "exploded_games_df['games'] = exploded_games_df['games'].str.split(',')\n",
    "exploded_games_df = exploded_games_df.explode('games').rename(columns = {'games': 'game_id', 'user':'user_id'})[['user_id', 'game_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>game_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>668788</td>\n",
       "      <td>668788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>335322</td>\n",
       "      <td>31425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>kj9521v8</td>\n",
       "      <td>k6q4rqzd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2059</td>\n",
       "      <td>6979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id   game_id\n",
       "count     668788    668788\n",
       "unique    335322     31425\n",
       "top     kj9521v8  k6q4rqzd\n",
       "freq        2059      6979"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploded_games_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bipartite_graph = nx.Graph()\n",
    "\n",
    "# Users have a bipartite value of 0, games have a bipartite value of 1.\n",
    "bipartite_graph.add_nodes_from(set(exploded_games_df['user_id'].values), bipartite=0)\n",
    "bipartite_graph.add_nodes_from(set(exploded_games_df['game_id'].values), bipartite=1)\n",
    "bipartite_graph.add_edges_from([(user, game) for user, game in zip(exploded_games_df['user_id'], exploded_games_df['game_id'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_bipartite(bipartite_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "del user_prefs_filename, user_prefs_df, exploded_games_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlapping Set Similarity with Limiting the Graph\n",
    "\n",
    "There are two methods of limiting the number of user-item interactions in our bipartite graph. We can either use the mean and standard deviation of the `num_games` column, or limit based on the integer number of games played by a given user. For example, we can either use three standard deviations of the mean to have a cutoff value of `24.2 (3 s.f.)`, or we can use the value of `2` for users that have played only one game.\n",
    "\n",
    "Using the method of standard deviations, we get a very similar output to the unlimited user-item interaction bipartite graph. We get popular games recommended most of the time. If we use the second approach, we get (anecdotally) more precise recommendations. However, the second method does not scale well, since we need to construct a different graph for each number of games played by each user. In reality, this isn't as bad as we think. Out of the 335,322 total users in our sample we can cover 306,371 users, or 91.4% (3 s.f.) of them with three graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_user_preferences_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df[(df['signup_date'].notna()) & (df['signup_date'] != \"Null\")]\n",
    "    df['signup_date'] = pd.to_datetime(df['signup_date'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "    df['signup_date'] = pd.to_datetime(df['signup_date'].dt.strftime('%Y-%m-%d'))\n",
    "    df = df[(df['signup_date'] < '2023-01-01')]\n",
    "    return df\n",
    "\n",
    "def limit_number_games_user_preferences_df(df: pd.DataFrame, num_games: int) -> pd.DataFrame:\n",
    "    return df[(df['num_games'] <= num_games)]\n",
    "\n",
    "def explode_games_played(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['games'] = df['games'].str.split(',')\n",
    "    return df.explode('games').rename(columns = {'games': 'game_id', 'user':'user_id'})\n",
    "\n",
    "def recommendation_graph_for_n_games_played(df: pd.DataFrame, n: int) -> tuple[pd.DataFrame, nx.Graph]:\n",
    "    df = clean_user_preferences_df(df)\n",
    "    df = limit_number_games_user_preferences_df(df, n+1)\n",
    "    df = explode_games_played(df)\n",
    "    bipartite_graph = nx.Graph()\n",
    "    bipartite_graph.add_nodes_from(set(df['user_id'].values), bipartite=0)\n",
    "    bipartite_graph.add_nodes_from(set(df['game_id'].values), bipartite=1)\n",
    "    bipartite_graph.add_edges_from([(user, game) for user, game in zip(df['user_id'], df['game_id'])])\n",
    "    return df, bipartite_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fp/pwtrzcy130zdfcx62mp9_kmc0000gn/T/ipykernel_2763/4036755379.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['signup_date'] = pd.to_datetime(df['signup_date'], format='%Y-%m-%dT%H:%M:%SZ')\n",
      "/var/folders/fp/pwtrzcy130zdfcx62mp9_kmc0000gn/T/ipykernel_2763/4036755379.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['signup_date'] = pd.to_datetime(df['signup_date'].dt.strftime('%Y-%m-%d'))\n"
     ]
    }
   ],
   "source": [
    "user_prefs_df = pd.read_csv('../data/users/user_preferences_with_metadata.csv')\n",
    "user_prefs_df, bipartite_graph = recommendation_graph_for_n_games_played(user_prefs_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_similarity(bipartite_graph: nx.Graph, total_item_nodes: int, user_a_id: str, user_b_id: str) -> float:\n",
    "    assert bipartite_graph.nodes[user_a_id]['bipartite'] == 0\n",
    "    assert bipartite_graph.nodes[user_b_id]['bipartite'] == 0\n",
    "\n",
    "    a_neighbours = bipartite_graph.neighbors(user_a_id)\n",
    "    b_neighbours = bipartite_graph.neighbors(user_b_id)\n",
    "    shared_nodes = set(a_neighbours).intersection(b_neighbours)\n",
    "\n",
    "    return len(shared_nodes) / total_item_nodes\n",
    "\n",
    "def most_similar_users(bipartite_graph: nx.Graph, user_id: str) -> tuple[list[str], float]:\n",
    "    all_users = set([user for user, value in bipartite_graph.nodes(data=True) if value['bipartite'] == 0])\n",
    "    all_users.remove(user_id)\n",
    "\n",
    "    total_item_nodes = 0\n",
    "    for _, values in bipartite_graph.nodes(data=True):\n",
    "        if values['bipartite'] == 1: total_item_nodes += 1\n",
    "\n",
    "    similarities = defaultdict(float)\n",
    "    for user in all_users:\n",
    "        similarities[user] = user_similarity(bipartite_graph, total_item_nodes, user_id, user)\n",
    "\n",
    "    max_similarity = max(similarities.values())\n",
    "    return [user for user, similarity in similarities.items() if similarity == max_similarity], max_similarity\n",
    "\n",
    "def recommend_games(bipartite_graph: nx.Graph, user_id: str) -> list[str]:\n",
    "    similar_users, _ = most_similar_users(bipartite_graph, user_id)\n",
    "    other_games = [game for user in similar_users for game in bipartite_graph.neighbors(user)]\n",
    "    game_rankings = Counter(other_games)\n",
    "\n",
    "    already_played_games = set(bipartite_graph.neighbors(user_id))\n",
    "\n",
    "    try:\n",
    "        [game_rankings.pop(game) for game in already_played_games]\n",
    "    except KeyError:\n",
    "        # If no other users in data set have played this game.\n",
    "        pass\n",
    "\n",
    "    ranked_games_in_order, _ = list(zip(*sorted(game_rankings.items(), key=itemgetter(1), reverse=True)))\n",
    "    \n",
    "    return ranked_games_in_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_metadata_df = pd.read_csv('../data/games/metadata/all_games.csv').rename(columns={'game_id': 'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Played games: ['Hello Neighbor' 'Super Mario Odyssey']\n",
      "Recommended games: [\"Baldi's Basics Category Extensions\" 'Google Quick Draw'\n",
      " 'Snipperclips: Cut it out  together!' 'Hello Neighbor 2' 'Cuphead'\n",
      " 'Super Mario Sunshine' 'Marble Saga: Kororinpa'\n",
      " 'The Legend of Zelda: The Wind Waker HD' 'Clicker Heroes'\n",
      " 'Minecraft: Java Edition' 'Island Saver'\n",
      " 'Super Mario Odyssey Category Extensions']\n"
     ]
    }
   ],
   "source": [
    "user = \"x355n6qj\"\n",
    "\n",
    "played_games = list(bipartite_graph.neighbors(user))\n",
    "print(f\"Played games: {games_metadata_df[(games_metadata_df['id'].isin(played_games))].game_name.values}\")\n",
    "\n",
    "recommended_games = recommend_games(bipartite_graph, user)\n",
    "print(f\"Recommended games: {games_metadata_df.set_index('id').loc(axis=0)[recommended_games].game_name.values[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "del games_metadata_df, played_games, recommended_games, user_prefs_df, bipartite_graph, user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Using a Game Similarity Matrix\n",
    "\n",
    "This recommendation method works by creating a matrix of how users have rated different games. We construct this matrix by rating a game `1` if a user has played it, and `0` if not. We then normalise these values by making the sum of ratings by each user equal to `1`. This is also called [scaling to a unit length](https://en.wikipedia.org/wiki/Feature_scaling#Scaling_to_unit_length). We take the dot product of the matrix and the transposed matrix, and this gives us the similarity between each item in the data set. The method is taken from [here](https://towardsdatascience.com/recommender-systems-item-customer-collaborative-filtering-ff0c8f41ae8a). **This method does not scale very well**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prefs_df = pd.read_csv('../data/users/user_preferences_with_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_user_prefs_df_to_ratings(df: pd.DataFrame, number_users=-1) -> pd.DataFrame:\n",
    "    tmp_df = df.copy()[:number_users]\n",
    "    tmp_df['games'] = tmp_df['games'].str.split(',')\n",
    "    tmp_df = tmp_df.explode('games').rename(columns = {'games': 'game_id', 'user':'user_id'})\n",
    "    tmp_df['rating'] = 1\n",
    "    return tmp_df[['user_id', 'game_id', 'rating']]\n",
    "\n",
    "def construct_similarity_matrix(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    tmp_df = df.copy()\n",
    "    tmp_df = pd.pivot_table(tmp_df, values='rating', index='user_id', columns='game_id')\n",
    "    tmp_df = tmp_df.fillna(0.0)\n",
    "    normalised_tmp_df = tmp_df / np.sqrt(np.square(tmp_df).sum(axis=0))\n",
    "    return normalised_tmp_df.transpose().dot(normalised_tmp_df)\n",
    "\n",
    "def construct_similar_games_df(df: pd.DataFrame, number_games: int) -> pd.DataFrame:\n",
    "    similar_games_df = pd.DataFrame(index=df.columns, columns=range(0, number_games + 1))\n",
    "    for i in range(0,len(df.columns)): \n",
    "        similar_games_df.iloc[i,:number_games+1] = df.iloc[0:,i].sort_values(ascending=False)[:number_games+1].index\n",
    "    return similar_games_df.loc[:,1:]\n",
    "\n",
    "def find_similar_games(df: pd.DataFrame, top_n_games=10):\n",
    "    similarity_matrix = construct_similarity_matrix(df)\n",
    "    similar_games_df = construct_similar_games_df(similarity_matrix, top_n_games)\n",
    "    return similar_games_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_games_df = pd.DataFrame()\n",
    "generate = False\n",
    "\n",
    "if generate:\n",
    "    ratings_df = format_user_prefs_df_to_ratings(user_prefs_df, number_users=70000)\n",
    "    similar_games_df = find_similar_games(ratings_df, 20)\n",
    "    similar_games_df.to_csv('./test.csv')\n",
    "else:\n",
    "    similar_games_df = pd.read_csv('../data/users/similarity_recommendations_70000_users.csv').set_index('game_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28541"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(similar_games_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_metadata_df = pd.read_csv('../data/games/metadata/all_games.csv').rename(columns={'game_id': 'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Played Game: LEGO Harry Potter: Years 5-7 (DS/PSP)\n",
      "Recommended games: ['LEGO Indiana Jones 2: The Adventure Continues (DS)'\n",
      " 'LEGO Star Wars II: The Original Trilogy (PSP)' 'Escape PS1 Hagrid'\n",
      " 'LEGO Star Wars III: The Clone Wars (DS)'\n",
      " 'LEGO Pirates of the Caribbean: The Video Game (DS)' 'Harry Obby'\n",
      " 'Demon Shift' 'Jumpix 2' 'Infinity Inc.' 'Kim Possible 3: Team Possible'\n",
      " 'Hannah Montana' 'Zubo' 'Multiple Handheld LEGO Games'\n",
      " 'LEGO Harry Potter: Years 1-4 (DS/PSP)' 'LEGO Batman: The Videogame (DS)'\n",
      " 'LEGO Star Wars II: The Original Trilogy (DS)'\n",
      " 'LEGO Indiana Jones: The Original Adventures (DS)'\n",
      " 'LEGO Harry Potter Category Extensions'\n",
      " 'LEGO Star Wars II: The Original Trilogy (GBA)'\n",
      " 'LEGO Star Wars: The Complete Saga (DS)']\n"
     ]
    }
   ],
   "source": [
    "game_id = \"kdkmzmx1\"\n",
    "print(f\"Played Game: {games_metadata_df.set_index('id').loc(axis=0)[game_id].game_name}\")\n",
    "recommended_games = similar_games_df.loc[game_id].values\n",
    "print(f\"Recommended games: {games_metadata_df.set_index('id').loc(axis=0)[recommended_games].game_name.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del game_id, generate, recommended_games, similar_games_df, user_prefs_df, games_metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation using Node2Vec Embeddings\n",
    "\n",
    "The idea behind using node2vec embeddings for recommendation is to predict future links that don't already exist. We can prove that this works for individual games recommendation by removing selected edges and using cosine similarity of embeddings to predict which edges should exist given this graph. We carry this on further by creating a pipeline to predict games to play when they are completely disconnected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_network_filter(filename: str, disallowed_games=None) -> dict[str, bool]:\n",
    "    with open(filename, 'r', encoding='utf-8') as openfile:\n",
    "        csv_reader = csv.reader(openfile)\n",
    "        next(csv_reader)\n",
    "        filter_map = defaultdict(bool)\n",
    "        for row in csv_reader:\n",
    "            # Check if the created/release date is after 2023, if it is then we can ignore it in the network.\n",
    "            release_date = datetime.strptime(row[3], \"%Y-%m-%d\")\n",
    "            if row[4] == \"None\":\n",
    "                # This is a completely random date before the final date.\n",
    "                row[4] = \"2017-10-22T05:21:29Z\"\n",
    "            created_date = datetime.strptime(row[4], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "            if disallowed_games == None:\n",
    "                disallowed_games = [\"y65797de\"]\n",
    "\n",
    "            if created_date < datetime(2023, 1, 1) and release_date < datetime(2023, 1, 1) and row[0] not in disallowed_games:\n",
    "                filter_map[row[0]] = True\n",
    "\n",
    "    return filter_map\n",
    "\n",
    "def get_weighted_edges_from_csv(filename: str, filter=None) -> list[tuple[str, str, int]]:\n",
    "    with open(filename, 'r', encoding='utf-8') as openfile:\n",
    "        csv_reader = csv.reader(openfile)\n",
    "        next(csv_reader)\n",
    "\n",
    "        edges = list()\n",
    "        for row in csv_reader:\n",
    "            if filter is None:\n",
    "                edges.append(tuple([row[0], row[1], int(row[2])]))\n",
    "                continue\n",
    "\n",
    "            if not filter.get(row[0]) or not filter.get(row[1]):\n",
    "                continue\n",
    "\n",
    "            edges.append(tuple([row[0], row[1], int(row[2])]))\n",
    "\n",
    "    return edges\n",
    "\n",
    "def create_weighted_graph(graph_filename: str, filter_filename: str):\n",
    "    filter_map = generate_network_filter(filter_filename)\n",
    "    edgelist = get_weighted_edges_from_csv(graph_filename, filter_map)\n",
    "    graph = nx.DiGraph()\n",
    "    graph.add_weighted_edges_from(edgelist)\n",
    "    return graph\n",
    "\n",
    "def generate_adjacency_matrix(graph: nx.DiGraph): \n",
    "    return nx.adjacency_matrix(graph, list(graph.nodes()))\n",
    "\n",
    "def generate_non_existing_edges(adj_graph: scipy.sparse.csr_matrix, node_list: list[str], number_samples: int):\n",
    "    non_existing_edges = []\n",
    "    offset = 0\n",
    "    for i in tqdm(range(adj_graph.shape[0])):\n",
    "        for j in range(offset, adj_graph.shape[1]):\n",
    "            if i != j:\n",
    "                if adj_graph[i, j] == 0:\n",
    "                    non_existing_edges.extend([node_list[i], node_list[j]])\n",
    "\n",
    "        offset += 1\n",
    "    return sorted(random.sample(non_existing_edges, k=number_samples))\n",
    "\n",
    "def get_removable_edges(graph: nx.DiGraph):\n",
    "    number_conected_components = nx.number_weakly_connected_components(graph)\n",
    "    number_nodes = len(graph.nodes())\n",
    "    tmp_graph = graph.copy()\n",
    "    removable_edges = []\n",
    "    for i in tqdm(list(tmp_graph.edges())):\n",
    "        tmp_graph.remove_edge(i)\n",
    "\n",
    "        if nx.number_weakly_connected_components(tmp_graph) == number_conected_components and \\\n",
    "            len(tmp_graph.nopdes()) == number_nodes:\n",
    "            removable_edges.append(i)\n",
    "            continue\n",
    "\n",
    "        tmp_graph.add_edge(i)\n",
    "    return removable_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30433, 30433)\n"
     ]
    }
   ],
   "source": [
    "adj_graph = None\n",
    "games_graph = create_weighted_graph('../data/too_big/all_games_filtered.csv', '../data/games/metadata/all_games.csv')\n",
    "generate = False\n",
    "\n",
    "if generate:\n",
    "    adj_graph = generate_adjacency_matrix(games_graph)\n",
    "    scipy.sparse.save_npz('../data/too_big/all_games_adjacency_matrix.npz', adj_graph)\n",
    "else:\n",
    "    adj_graph = scipy.sparse.load_npz('../data/too_big/all_games_adjacency_matrix.npz')\n",
    "print(adj_graph.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_existing_edges = generate_non_existing_edges(adj_graph, list(games_graph.nodes()), 4000)\n",
    "non_existing_edges_df = pd.DataFrame(data=non_existing_edges, columns=['source', 'target'])\n",
    "non_existing_edges_df['connection'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removable_edges = get_removable_edges(games_graph)\n",
    "removable_edges_df = pd.DataFrame(data=removable_edges, columns=['source', 'target'])\n",
    "removable_edges_df['connection'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = non_existing_edges_df.append(removable_edges_df, ignore_index=True)\n",
    "graph_without_edges = games_graph.copy().remove_edges_from(removable_edges)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed225720166559e7176d3793db16a2fd8d295f725007103b21ac3099d2a89ee8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
