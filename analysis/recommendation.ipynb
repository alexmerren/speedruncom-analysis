{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Systems for Speedrun.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation by User ID using Bipartite Graph\n",
    "\n",
    "This method of recommendation works by finding other users that have played the same game as a target user. The games that the other users have played are ranked by occurrence. Games that the target user has not played but the other users have played are then recommended in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from operator import itemgetter\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prefs_filename = \"../data/users/user_preferences_with_metadata.csv\"\n",
    "user_prefs_df = pd.read_csv(user_prefs_filename)\n",
    "user_prefs_df = user_prefs_df[(user_prefs_df['signup_date'].notna()) & (user_prefs_df['signup_date'] != \"Null\")]\n",
    "user_prefs_df['signup_date'] = pd.to_datetime(user_prefs_df['signup_date'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "user_prefs_df['signup_date'] = pd.to_datetime(user_prefs_df['signup_date'].dt.strftime('%Y-%m-%d'))\n",
    "user_prefs_df = user_prefs_df[(user_prefs_df['signup_date'] < '2023-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>signup_date</th>\n",
       "      <th>location</th>\n",
       "      <th>num_games</th>\n",
       "      <th>games</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>335322</td>\n",
       "      <td>335322</td>\n",
       "      <td>335322</td>\n",
       "      <td>335322.000000</td>\n",
       "      <td>335322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>335322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>j5wzz2qj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>k6q4rqzd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-28 13:40:53.271780608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.994465</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-01-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-09-16 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-25 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2059.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.410692</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user                    signup_date location      num_games  \\\n",
       "count     335322                         335322   335322  335322.000000   \n",
       "unique    335322                            NaN      257            NaN   \n",
       "top     j5wzz2qj                            NaN       us            NaN   \n",
       "freq           1                            NaN   101439            NaN   \n",
       "mean         NaN  2020-06-28 13:40:53.271780608      NaN       1.994465   \n",
       "min          NaN            2014-01-06 00:00:00      NaN       1.000000   \n",
       "25%          NaN            2019-09-16 00:00:00      NaN       1.000000   \n",
       "50%          NaN            2021-01-04 00:00:00      NaN       1.000000   \n",
       "75%          NaN            2021-09-25 00:00:00      NaN       2.000000   \n",
       "max          NaN            2022-12-31 00:00:00      NaN    2059.000000   \n",
       "std          NaN                            NaN      NaN       7.410692   \n",
       "\n",
       "           games  \n",
       "count     335322  \n",
       "unique     88806  \n",
       "top     k6q4rqzd  \n",
       "freq        5131  \n",
       "mean         NaN  \n",
       "min          NaN  \n",
       "25%          NaN  \n",
       "50%          NaN  \n",
       "75%          NaN  \n",
       "max          NaN  \n",
       "std          NaN  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prefs_df.describe(include='all', datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_games_df = user_prefs_df.copy()\n",
    "exploded_games_df['games'] = exploded_games_df['games'].str.split(',')\n",
    "exploded_games_df = exploded_games_df.explode('games').rename(columns = {'games': 'game_id', 'user':'user_id'})[['user_id', 'game_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>game_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>668788</td>\n",
       "      <td>668788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>335322</td>\n",
       "      <td>31425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>kj9521v8</td>\n",
       "      <td>k6q4rqzd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2059</td>\n",
       "      <td>6979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id   game_id\n",
       "count     668788    668788\n",
       "unique    335322     31425\n",
       "top     kj9521v8  k6q4rqzd\n",
       "freq        2059      6979"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploded_games_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bipartite_graph = nx.Graph()\n",
    "\n",
    "# Users have a bipartite value of 0, games have a bipartite value of 1.\n",
    "bipartite_graph.add_nodes_from(set(exploded_games_df['user_id'].values), bipartite=0)\n",
    "bipartite_graph.add_nodes_from(set(exploded_games_df['game_id'].values), bipartite=1)\n",
    "bipartite_graph.add_edges_from([(user, game) for user, game in zip(exploded_games_df['user_id'], exploded_games_df['game_id'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_bipartite(bipartite_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "del user_prefs_filename, user_prefs_df, exploded_games_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlapping Set Similarity with Limiting the Graph\n",
    "\n",
    "There are two methods of limiting the number of user-item interactions in our bipartite graph. We can either use the mean and standard deviation of the `num_games` column, or limit based on the integer number of games played by a given user. For example, we can either use three standard deviations of the mean to have a cutoff value of `24.2 (3 s.f.)`, or we can use the value of `2` for users that have played only one game.\n",
    "\n",
    "Using the method of standard deviations, we get a very similar output to the unlimited user-item interaction bipartite graph. We get popular games recommended most of the time. If we use the second approach, we get (anecdotally) more precise recommendations. However, the second method does not scale well, since we need to construct a different graph for each number of games played by each user. In reality, this isn't as bad as we think. Out of the 335,322 total users in our sample we can cover 306,371 users, or 91.4% (3 s.f.) of them with three graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_user_preferences_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df[(df['signup_date'].notna()) & (df['signup_date'] != \"Null\")]\n",
    "    df['signup_date'] = pd.to_datetime(df['signup_date'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "    df['signup_date'] = pd.to_datetime(df['signup_date'].dt.strftime('%Y-%m-%d'))\n",
    "    df = df[(df['signup_date'] < '2023-01-01')]\n",
    "    return df\n",
    "\n",
    "def limit_number_games_user_preferences_df(df: pd.DataFrame, num_games: int) -> pd.DataFrame:\n",
    "    return df[(df['num_games'] <= num_games)]\n",
    "\n",
    "def explode_games_played(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['games'] = df['games'].str.split(',')\n",
    "    return df.explode('games').rename(columns = {'games': 'game_id', 'user':'user_id'})\n",
    "\n",
    "def recommendation_graph_for_n_games_played(df: pd.DataFrame, n: int) -> tuple[pd.DataFrame, nx.Graph]:\n",
    "    df = clean_user_preferences_df(df)\n",
    "    df = limit_number_games_user_preferences_df(df, n+1)\n",
    "    df = explode_games_played(df)\n",
    "    bipartite_graph = nx.Graph()\n",
    "    bipartite_graph.add_nodes_from(set(df['user_id'].values), bipartite=0)\n",
    "    bipartite_graph.add_nodes_from(set(df['game_id'].values), bipartite=1)\n",
    "    bipartite_graph.add_edges_from([(user, game) for user, game in zip(df['user_id'], df['game_id'])])\n",
    "    return df, bipartite_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fp/pwtrzcy130zdfcx62mp9_kmc0000gn/T/ipykernel_2763/4036755379.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['signup_date'] = pd.to_datetime(df['signup_date'], format='%Y-%m-%dT%H:%M:%SZ')\n",
      "/var/folders/fp/pwtrzcy130zdfcx62mp9_kmc0000gn/T/ipykernel_2763/4036755379.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['signup_date'] = pd.to_datetime(df['signup_date'].dt.strftime('%Y-%m-%d'))\n"
     ]
    }
   ],
   "source": [
    "user_prefs_df = pd.read_csv('../data/users/user_preferences_with_metadata.csv')\n",
    "user_prefs_df, bipartite_graph = recommendation_graph_for_n_games_played(user_prefs_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_similarity(bipartite_graph: nx.Graph, total_item_nodes: int, user_a_id: str, user_b_id: str) -> float:\n",
    "    assert bipartite_graph.nodes[user_a_id]['bipartite'] == 0\n",
    "    assert bipartite_graph.nodes[user_b_id]['bipartite'] == 0\n",
    "\n",
    "    a_neighbours = bipartite_graph.neighbors(user_a_id)\n",
    "    b_neighbours = bipartite_graph.neighbors(user_b_id)\n",
    "    shared_nodes = set(a_neighbours).intersection(b_neighbours)\n",
    "\n",
    "    return len(shared_nodes) / total_item_nodes\n",
    "\n",
    "def most_similar_users(bipartite_graph: nx.Graph, user_id: str) -> tuple[list[str], float]:\n",
    "    all_users = set([user for user, value in bipartite_graph.nodes(data=True) if value['bipartite'] == 0])\n",
    "    all_users.remove(user_id)\n",
    "\n",
    "    total_item_nodes = 0\n",
    "    for _, values in bipartite_graph.nodes(data=True):\n",
    "        if values['bipartite'] == 1: total_item_nodes += 1\n",
    "\n",
    "    similarities = defaultdict(float)\n",
    "    for user in all_users:\n",
    "        similarities[user] = user_similarity(bipartite_graph, total_item_nodes, user_id, user)\n",
    "\n",
    "    max_similarity = max(similarities.values())\n",
    "    return [user for user, similarity in similarities.items() if similarity == max_similarity], max_similarity\n",
    "\n",
    "def recommend_games(bipartite_graph: nx.Graph, user_id: str) -> list[str]:\n",
    "    similar_users, _ = most_similar_users(bipartite_graph, user_id)\n",
    "    other_games = [game for user in similar_users for game in bipartite_graph.neighbors(user)]\n",
    "    game_rankings = Counter(other_games)\n",
    "\n",
    "    already_played_games = set(bipartite_graph.neighbors(user_id))\n",
    "\n",
    "    try:\n",
    "        [game_rankings.pop(game) for game in already_played_games]\n",
    "    except KeyError:\n",
    "        # If no other users in data set have played this game.\n",
    "        pass\n",
    "\n",
    "    ranked_games_in_order, _ = list(zip(*sorted(game_rankings.items(), key=itemgetter(1), reverse=True)))\n",
    "    \n",
    "    return ranked_games_in_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_metadata_df = pd.read_csv('../data/games/metadata/all_games.csv').rename(columns={'game_id': 'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Played games: ['Hello Neighbor' 'Super Mario Odyssey']\n",
      "Recommended games: [\"Baldi's Basics Category Extensions\" 'Google Quick Draw'\n",
      " 'Snipperclips: Cut it out  together!' 'Hello Neighbor 2' 'Cuphead'\n",
      " 'Super Mario Sunshine' 'Marble Saga: Kororinpa'\n",
      " 'The Legend of Zelda: The Wind Waker HD' 'Clicker Heroes'\n",
      " 'Minecraft: Java Edition' 'Island Saver'\n",
      " 'Super Mario Odyssey Category Extensions']\n"
     ]
    }
   ],
   "source": [
    "user = \"x355n6qj\"\n",
    "\n",
    "played_games = list(bipartite_graph.neighbors(user))\n",
    "print(f\"Played games: {games_metadata_df[(games_metadata_df['id'].isin(played_games))].game_name.values}\")\n",
    "\n",
    "recommended_games = recommend_games(bipartite_graph, user)\n",
    "print(f\"Recommended games: {games_metadata_df.set_index('id').loc(axis=0)[recommended_games].game_name.values[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "del games_metadata_df, played_games, recommended_games, user_prefs_df, bipartite_graph, user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Using a Game Similarity Matrix\n",
    "\n",
    "This recommendation method works by creating a matrix of how users have rated different games. We construct this matrix by rating a game `1` if a user has played it, and `0` if not. We then normalise these values by making the sum of ratings by each user equal to `1`. This is also called [scaling to a unit length](https://en.wikipedia.org/wiki/Feature_scaling#Scaling_to_unit_length). We take the dot product of the matrix and the transposed matrix, and this gives us the similarity between each item in the data set. The method is taken from [here](https://towardsdatascience.com/recommender-systems-item-customer-collaborative-filtering-ff0c8f41ae8a). **This method does not scale very well**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prefs_df = pd.read_csv('../data/users/user_preferences_with_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_user_prefs_df_to_ratings(df: pd.DataFrame, number_users=-1) -> pd.DataFrame:\n",
    "    tmp_df = df.copy()[:number_users]\n",
    "    tmp_df['games'] = tmp_df['games'].str.split(',')\n",
    "    tmp_df = tmp_df.explode('games').rename(columns = {'games': 'game_id', 'user':'user_id'})\n",
    "    tmp_df['rating'] = 1\n",
    "    return tmp_df[['user_id', 'game_id', 'rating']]\n",
    "\n",
    "def construct_similarity_matrix(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    tmp_df = df.copy()\n",
    "    tmp_df = pd.pivot_table(tmp_df, values='rating', index='user_id', columns='game_id')\n",
    "    tmp_df = tmp_df.fillna(0.0)\n",
    "    normalised_tmp_df = tmp_df / np.sqrt(np.square(tmp_df).sum(axis=0))\n",
    "    return normalised_tmp_df.transpose().dot(normalised_tmp_df)\n",
    "\n",
    "def recommend_from_game(similarity_matrix: pd.DataFrame, game_id: str, n_recommendations: int) -> list[str]:\n",
    "    return similarity_matrix.nlargest(n_recommendations+1, game_id).index.values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = pd.DataFrame()\n",
    "generate = False\n",
    "\n",
    "if generate:\n",
    "    ratings_df = format_user_prefs_df_to_ratings(user_prefs_df, number_users=5000)\n",
    "    similarity_matrix = construct_similarity_matrix(ratings_df)\n",
    "    similarity_matrix.to_csv('./test.csv')\n",
    "else:\n",
    "    similarity_matrix = pd.read_csv('../data/users/game_similarity_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = similarity_matrix.set_index('game_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_metadata_df = pd.read_csv('../data/games/metadata/all_games.csv').rename(columns={'game_id': 'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Played Game: LEGO Harry Potter: Years 5-7 (DS/PSP)\n",
      "Recommended games: ['LEGO Indiana Jones 2: The Adventure Continues (DS)'\n",
      " 'LEGO Star Wars II: The Original Trilogy (PSP)' 'Escape PS1 Hagrid'\n",
      " 'LEGO Star Wars III: The Clone Wars (DS)'\n",
      " 'LEGO Pirates of the Caribbean: The Video Game (DS)']\n"
     ]
    }
   ],
   "source": [
    "game_id = \"kdkmzmx1\"\n",
    "n = 5\n",
    "recommended_games = recommend_from_game(similarity_matrix, game_id, n)\n",
    "\n",
    "print(f\"Played Game: {games_metadata_df.set_index('id').loc(axis=0)[game_id].game_name}\")\n",
    "print(f\"Recommended games: {games_metadata_df.set_index('id').loc(axis=0)[recommended_games].game_name.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del game_id, generate, recommended_games, user_prefs_df, games_metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics of Cosine Similarity CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_user_prefs_df_to_ratings(df: pd.DataFrame, number_users=-1) -> pd.DataFrame:\n",
    "    tmp_df = df.copy()[:number_users]\n",
    "    tmp_df['games'] = tmp_df['games'].str.split(',')\n",
    "    tmp_df = tmp_df.explode('games').rename(columns = {'games': 'game_id', 'user':'user_id'})\n",
    "    tmp_df['rating'] = 1\n",
    "    return tmp_df[['user_id', 'game_id', 'rating']]\n",
    "\n",
    "def construct_similarity_matrix(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    tmp_df = df.copy()\n",
    "    tmp_df = pd.pivot_table(tmp_df, values='rating', index='user_id', columns='game_id')\n",
    "    tmp_df = tmp_df.fillna(0.0)\n",
    "    normalised_tmp_df = tmp_df / np.sqrt(np.square(tmp_df).sum(axis=0))\n",
    "    return normalised_tmp_df.transpose().dot(normalised_tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prefs_df = pd.read_csv('../data/users/user_preferences_with_metadata.csv').sort_values(by='num_games', ascending=True)[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(user_prefs_df, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create cosine similarity matrix for test data, create recommendation engine using that cosine similarity matrix. \n",
    "train_df = format_user_prefs_df_to_ratings(train_df)\n",
    "similarity_matrix_t = construct_similarity_matrix(train_df)\n",
    "\n",
    "# Find the games played by the test users. Only use them if they play more than one game.\n",
    "recommendations = []\n",
    "unique_games_in_test = np.unique(test_df['games'].str.split(',').tolist()[0])\n",
    "for game in unique_games_in_test:\n",
    "    game_row = similarity_matrix_t.loc[game]\n",
    "    recs = game_row[(game_row > 0.5).any() & (game_row != 1.0)].index.values.tolist()[0]\n",
    "    recommendations.append(recs)\n",
    "\n",
    "relevant_games_set = [set(games) for games in unique_games_in_test]\n",
    "recommended_games_set = [set(games) for games in recommendations]\n",
    "intersection = [len(recommended.intersection(relevant)) for recommended, relevant in zip(recommended_games_set, relevant_games_set)]\n",
    "recall = np.mean([i/len(relevant) for i, relevant in zip(intersection, relevant_games_set)])\n",
    "precision = np.mean([i/len(recommended) for i, recommended in zip(intersection, recommended_games_set)])\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.5\n",
      "Precision: 0.6666666666666666\n",
      "F1-score: 0.5714285714285715\n"
     ]
    }
   ],
   "source": [
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"F1-score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation using Node2Vec Embeddings\n",
    "\n",
    "The idea behind using node2vec embeddings for recommendation is to predict future links that don't already exist. We can prove that this works for individual games recommendation by removing selected edges and using cosine similarity of embeddings to predict which edges should exist given this graph. We carry this on further by creating a pipeline to predict games to play when they are completely disconnected.\n",
    "\n",
    "Do [this](https://sparsh-ai.github.io/rec-tutorials/graph%20embedding%20movielens%20factorization/2021/04/24/Recommendation-Node2vec.html)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, auc, roc_curve, roc_auc_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_existence_df = pd.read_csv('../data/games/network/edge_existence_dataset.csv').set_index('index')\n",
    "embeddings_df = pd.read_csv('../data/games/network/homophily.emb', delimiter=\" \", skiprows=1, index_col=0, header=None).rename(columns={0: 'id'}).add_prefix(\"dim_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_features = [(embeddings_df.loc[node1].values.tolist()+embeddings_df.loc[node2].values.tolist()) for node1, node2 in zip(edge_existence_df[\"source\"], edge_existence_df[\"target\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(edge_features)\n",
    "y = edge_existence_df['connection']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10471, 32), (10471,))"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max. accuracy):  {'max_depth': 15, 'n_estimators': 50}\n",
      "Grid best score (accuracy):  0.9985675631933949\n",
      "Test set AUC:  0.999998330779426\n",
      "Grid best parameter (max. AUC):  {'max_depth': 10, 'n_estimators': 50}\n",
      "Grid best score (AUC):  0.9999765448696089\n"
     ]
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier()\n",
    " \n",
    "# parameters\n",
    "param = {'n_estimators' : [10,50,100], 'max_depth' : [5,10,15]}\n",
    " \n",
    "# model\n",
    "grid_clf_acc1 = GridSearchCV(clf1, param_grid = param)\n",
    " \n",
    "# train the model\n",
    "grid_clf_acc1.fit(X_train, y_train)\n",
    " \n",
    "print('Grid best parameter (max. accuracy): ', grid_clf_acc1.best_params_)\n",
    "print('Grid best score (accuracy): ', grid_clf_acc1.best_score_)\n",
    " \n",
    "# alternative metric to optimize over grid parameters: AUC\n",
    "grid_clf_auc1 = GridSearchCV(clf1, param_grid = param, scoring = 'roc_auc')\n",
    "grid_clf_auc1.fit(X_train, y_train)\n",
    "predict_proba = grid_clf_auc1.predict_proba(X_test)[:,1]\n",
    " \n",
    "print('Test set AUC: ', roc_auc_score(y_test, predict_proba))\n",
    "print('Grid best parameter (max. AUC): ', grid_clf_auc1.best_params_)\n",
    "print('Grid best score (AUC): ', grid_clf_auc1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 929,    0],\n",
       "       [  10, 2552]], dtype=int64)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(grid_clf_auc1.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 64 features, but RandomForestClassifier is expecting 32 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\ajcm203\\speedruncom-data\\analysis\\recommendation.ipynb Cell 40'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ajcm203/speedruncom-data/analysis/recommendation.ipynb#ch0000056?line=3'>4</a>\u001b[0m SM64 \u001b[39m=\u001b[39m [\u001b[39m-\u001b[39m\u001b[39m0.012588676\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.029154047\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0028756857\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.009487752\u001b[39m, \u001b[39m0.017457027\u001b[39m, \u001b[39m0.0210394\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.010649294\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0018646903\u001b[39m, \u001b[39m0.022166133\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.024311021\u001b[39m, \u001b[39m0.0062766\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.029152796\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.030749485\u001b[39m, \u001b[39m0.0017411523\u001b[39m, \u001b[39m0.029207725\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.015724432\u001b[39m, \u001b[39m0.009961858\u001b[39m, \u001b[39m0.008669887\u001b[39m, \u001b[39m0.01067755\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.012766957\u001b[39m, \u001b[39m0.0050436445\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0035253912\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.008545488\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.022413097\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.014777329\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.005886156\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.024985388\u001b[39m, \u001b[39m0.004289292\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0025947131\u001b[39m, \u001b[39m0.0019044504\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.014002968\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.02486419\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ajcm203/speedruncom-data/analysis/recommendation.ipynb#ch0000056?line=5'>6</a>\u001b[0m smo_sm64_features \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(SMO \u001b[39m+\u001b[39m SM64)\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ajcm203/speedruncom-data/analysis/recommendation.ipynb#ch0000056?line=6'>7</a>\u001b[0m grid_clf_auc1\u001b[39m.\u001b[39;49mpredict(smo_sm64_features)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:113\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/metaestimators.py?line=109'>110</a>\u001b[0m         \u001b[39mraise\u001b[39;00m attr_err\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/metaestimators.py?line=111'>112</a>\u001b[0m     \u001b[39m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/metaestimators.py?line=112'>113</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(obj, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# noqa\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/metaestimators.py?line=113'>114</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/metaestimators.py?line=115'>116</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:521\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=502'>503</a>\u001b[0m \u001b[39m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=503'>504</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=504'>505</a>\u001b[0m \u001b[39mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=517'>518</a>\u001b[0m \u001b[39m    the best found parameters.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=518'>519</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=519'>520</a>\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=520'>521</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_estimator_\u001b[39m.\u001b[39;49mpredict(X)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:808\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=786'>787</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=787'>788</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=788'>789</a>\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=789'>790</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=805'>806</a>\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=806'>807</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=807'>808</a>\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=809'>810</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=810'>811</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:850\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=847'>848</a>\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=848'>849</a>\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=849'>850</a>\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=851'>852</a>\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=852'>853</a>\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:579\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=575'>576</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=576'>577</a>\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=577'>578</a>\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=578'>579</a>\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=579'>580</a>\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/ensemble/_forest.py?line=580'>581</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/base.py?line=581'>582</a>\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/base.py?line=583'>584</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/base.py?line=584'>585</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/base.py?line=586'>587</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/base.py?line=396'>397</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/base.py?line=398'>399</a>\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/base.py?line=399'>400</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/base.py?line=400'>401</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/base.py?line=401'>402</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/base.py?line=402'>403</a>\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 64 features, but RandomForestClassifier is expecting 32 features as input."
     ]
    }
   ],
   "source": [
    "# Test if there is a link between super mario odyssey and super mario 64 (there is).\n",
    "# IDs: 76r55vd8 o1y9wo6q\n",
    "SMO = [0.003971752, 0.00646716, 0.005253054, 0.000770621, 0.023088027, -0.0025586337, 0.021919776, 0.023069408, 0.00055524334, 0.018905181, -0.015266668, -0.0029585548, 0.010636453, -0.017556641, -0.0020937473, -0.029378641, 0.013062697, -0.009451449, -0.020212192, 0.017371856, 0.003602054, -0.026192848, -0.025948, 0.017900482, 0.02082228, -0.019447599, 0.020568952, 0.025263663, -0.01999519, -0.023548912, -0.019287951, -0.011146348]\n",
    "SM64 = [-0.012588676, -0.029154047, -0.0028756857, -0.009487752, 0.017457027, 0.0210394, -0.010649294, -0.0018646903, 0.022166133, -0.024311021, 0.0062766, -0.029152796, -0.030749485, 0.0017411523, 0.029207725, -0.015724432, 0.009961858, 0.008669887, 0.01067755, -0.012766957, 0.0050436445, -0.0035253912, -0.008545488, -0.022413097, -0.014777329, -0.005886156, -0.024985388, 0.004289292, -0.0025947131, 0.0019044504, -0.014002968, -0.02486419]\n",
    "\n",
    "smo_sm64_features = np.array(SMO + SM64).reshape(1, -1)\n",
    "grid_clf_auc1.predict(smo_sm64_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uhoh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\ajcm203\\speedruncom-data\\analysis\\recommendation.ipynb Cell 40'\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ajcm203/speedruncom-data/analysis/recommendation.ipynb#ch0000057?line=13'>14</a>\u001b[0m grid_clf_acc3 \u001b[39m=\u001b[39m GridSearchCV(clf3, param_grid \u001b[39m=\u001b[39m param)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ajcm203/speedruncom-data/analysis/recommendation.ipynb#ch0000057?line=15'>16</a>\u001b[0m \u001b[39m# train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/ajcm203/speedruncom-data/analysis/recommendation.ipynb#ch0000057?line=16'>17</a>\u001b[0m grid_clf_acc3\u001b[39m.\u001b[39;49mfit(X_train_scaled, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ajcm203/speedruncom-data/analysis/recommendation.ipynb#ch0000057?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mGrid best parameter (max. accuracy): \u001b[39m\u001b[39m'\u001b[39m, grid_clf_acc3\u001b[39m.\u001b[39mbest_params_)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ajcm203/speedruncom-data/analysis/recommendation.ipynb#ch0000057?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mGrid best score (accuracy): \u001b[39m\u001b[39m'\u001b[39m, grid_clf_acc3\u001b[39m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=884'>885</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=885'>886</a>\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=886'>887</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=888'>889</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=890'>891</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=892'>893</a>\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=893'>894</a>\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=894'>895</a>\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=1389'>1390</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=1390'>1391</a>\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=1391'>1392</a>\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=829'>830</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=830'>831</a>\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=831'>832</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=832'>833</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=833'>834</a>\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=834'>835</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=835'>836</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=837'>838</a>\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=838'>839</a>\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=839'>840</a>\u001b[0m         clone(base_estimator),\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=840'>841</a>\u001b[0m         X,\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=841'>842</a>\u001b[0m         y,\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=842'>843</a>\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=843'>844</a>\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=844'>845</a>\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=845'>846</a>\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=846'>847</a>\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=847'>848</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=848'>849</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=849'>850</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=850'>851</a>\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=851'>852</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=852'>853</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=854'>855</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=855'>856</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=856'>857</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=857'>858</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=858'>859</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_search.py?line=859'>860</a>\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=1042'>1043</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=1043'>1044</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=1045'>1046</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=1046'>1047</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=1049'>1050</a>\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=1050'>1051</a>\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=1051'>1052</a>\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=858'>859</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=859'>860</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=860'>861</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=861'>862</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=776'>777</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=777'>778</a>\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=778'>779</a>\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=779'>780</a>\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=780'>781</a>\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=781'>782</a>\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=782'>783</a>\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=783'>784</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/_parallel_backends.py?line=205'>206</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/_parallel_backends.py?line=206'>207</a>\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/_parallel_backends.py?line=207'>208</a>\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/_parallel_backends.py?line=208'>209</a>\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/_parallel_backends.py?line=209'>210</a>\u001b[0m         callback(result)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/_parallel_backends.py?line=568'>569</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/_parallel_backends.py?line=569'>570</a>\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/_parallel_backends.py?line=570'>571</a>\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/_parallel_backends.py?line=571'>572</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/fixes.py?line=213'>214</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/fixes.py?line=214'>215</a>\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/fixes.py?line=215'>216</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_validation.py?line=677'>678</a>\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_validation.py?line=678'>679</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_validation.py?line=679'>680</a>\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_validation.py?line=681'>682</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_validation.py?line=682'>683</a>\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/model_selection/_validation.py?line=683'>684</a>\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:752\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=734'>735</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=735'>736</a>\u001b[0m     \u001b[39m\"\"\"Fit the model to data matrix X and target(s) y.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=736'>737</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=737'>738</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=749'>750</a>\u001b[0m \u001b[39m        Returns a trained MLP model.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=750'>751</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=751'>752</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, incremental\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:440\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=437'>438</a>\u001b[0m \u001b[39m# Run the LBFGS solver\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=438'>439</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msolver \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=439'>440</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_lbfgs(\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=440'>441</a>\u001b[0m         X, y, activations, deltas, coef_grads, intercept_grads, layer_units\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=441'>442</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=442'>443</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:536\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit_lbfgs\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=532'>533</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=533'>534</a>\u001b[0m     iprint \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=535'>536</a>\u001b[0m opt_res \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49moptimize\u001b[39m.\u001b[39;49mminimize(\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=536'>537</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_loss_grad_lbfgs,\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=537'>538</a>\u001b[0m     packed_coef_inter,\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=538'>539</a>\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mL-BFGS-B\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=539'>540</a>\u001b[0m     jac\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=540'>541</a>\u001b[0m     options\u001b[39m=\u001b[39;49m{\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=541'>542</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmaxfun\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_fun,\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=542'>543</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmaxiter\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=543'>544</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39miprint\u001b[39;49m\u001b[39m\"\u001b[39;49m: iprint,\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=544'>545</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mgtol\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=545'>546</a>\u001b[0m     },\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=546'>547</a>\u001b[0m     args\u001b[39m=\u001b[39;49m(X, y, activations, deltas, coef_grads, intercept_grads),\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=547'>548</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=548'>549</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m _check_optimize_result(\u001b[39m\"\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m\"\u001b[39m, opt_res, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=549'>550</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_ \u001b[39m=\u001b[39m opt_res\u001b[39m.\u001b[39mfun\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\_minimize.py:623\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_minimize.py?line=619'>620</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_minimize.py?line=620'>621</a>\u001b[0m                               \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_minimize.py?line=621'>622</a>\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_minimize.py?line=622'>623</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_minimize.py?line=623'>624</a>\u001b[0m                             callback\u001b[39m=\u001b[39mcallback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_minimize.py?line=624'>625</a>\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_minimize.py?line=625'>626</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_minimize.py?line=626'>627</a>\u001b[0m                          \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py:360\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/lbfgsb.py?line=353'>354</a>\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/lbfgsb.py?line=354'>355</a>\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/lbfgsb.py?line=355'>356</a>\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/lbfgsb.py?line=356'>357</a>\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/lbfgsb.py?line=357'>358</a>\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/lbfgsb.py?line=358'>359</a>\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/lbfgsb.py?line=359'>360</a>\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/lbfgsb.py?line=360'>361</a>\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/lbfgsb.py?line=361'>362</a>\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/lbfgsb.py?line=362'>363</a>\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:267\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_differentiable_functions.py?line=264'>265</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx):\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_differentiable_functions.py?line=265'>266</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_differentiable_functions.py?line=266'>267</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_differentiable_functions.py?line=267'>268</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_grad()\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_differentiable_functions.py?line=268'>269</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:233\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_differentiable_functions.py?line=230'>231</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_differentiable_functions.py?line=231'>232</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_differentiable_functions.py?line=232'>233</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_differentiable_functions.py?line=233'>234</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_differentiable_functions.py?line=135'>136</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_differentiable_functions.py?line=136'>137</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:134\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_differentiable_functions.py?line=129'>130</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_differentiable_functions.py?line=130'>131</a>\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_differentiable_functions.py?line=131'>132</a>\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_differentiable_functions.py?line=132'>133</a>\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/_differentiable_functions.py?line=133'>134</a>\u001b[0m \u001b[39mreturn\u001b[39;00m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\optimize.py:74\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/optimize.py?line=71'>72</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs):\n\u001b[0;32m     <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/optimize.py?line=72'>73</a>\u001b[0m     \u001b[39m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/optimize.py?line=73'>74</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_if_needed(x, \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m     <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/optimize.py?line=74'>75</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\optimize.py:68\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/optimize.py?line=65'>66</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(x \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/optimize.py?line=66'>67</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m---> <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/optimize.py?line=67'>68</a>\u001b[0m     fg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfun(x, \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m     <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/optimize.py?line=68'>69</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39m=\u001b[39m fg[\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='file:///c%3A/Anaconda/lib/site-packages/scipy/optimize/optimize.py?line=69'>70</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m fg[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:234\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._loss_grad_lbfgs\u001b[1;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=192'>193</a>\u001b[0m \u001b[39m\"\"\"Compute the MLP loss function and its corresponding derivatives\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=193'>194</a>\u001b[0m \u001b[39mwith respect to the different parameters given in the initialization.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=194'>195</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=230'>231</a>\u001b[0m \u001b[39mgrad : array-like, shape (number of nodes of all layers,)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=231'>232</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=232'>233</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unpack(packed_coef_inter)\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=233'>234</a>\u001b[0m loss, coef_grads, intercept_grads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backprop(\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=234'>235</a>\u001b[0m     X, y, activations, deltas, coef_grads, intercept_grads\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=235'>236</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=236'>237</a>\u001b[0m grad \u001b[39m=\u001b[39m _pack(coef_grads, intercept_grads)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=237'>238</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss, grad\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:310\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._backprop\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=307'>308</a>\u001b[0m \u001b[39m# Iterate over the hidden layers\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=308'>309</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_layers_ \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=309'>310</a>\u001b[0m     deltas[i \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m safe_sparse_dot(deltas[i], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoefs_[i]\u001b[39m.\u001b[39;49mT)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=310'>311</a>\u001b[0m     inplace_derivative(activations[i], deltas[i \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m])\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=312'>313</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_loss_grad(\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=313'>314</a>\u001b[0m         i \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, n_samples, activations, deltas, coef_grads, intercept_grads\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=314'>315</a>\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\extmath.py:153\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/extmath.py?line=150'>151</a>\u001b[0m         ret \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(a, b)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/extmath.py?line=151'>152</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/extmath.py?line=152'>153</a>\u001b[0m     ret \u001b[39m=\u001b[39m a \u001b[39m@\u001b[39;49m b\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/extmath.py?line=154'>155</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/extmath.py?line=155'>156</a>\u001b[0m     sparse\u001b[39m.\u001b[39missparse(a)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/extmath.py?line=156'>157</a>\u001b[0m     \u001b[39mand\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(b)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/extmath.py?line=157'>158</a>\u001b[0m     \u001b[39mand\u001b[39;00m dense_output\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/extmath.py?line=158'>159</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ret, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/extmath.py?line=159'>160</a>\u001b[0m ):\n\u001b[0;32m    <a href='file:///c%3A/Anaconda/lib/site-packages/sklearn/utils/extmath.py?line=160'>161</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39mtoarray()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# classifier\n",
    "clf3 = MLPClassifier(max_iter=1000)\n",
    " \n",
    "# scaling training and test sets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    " \n",
    "# parameters\n",
    "param = {'hidden_layer_sizes' : [10,100,[10,10]], 'activation' : ['tanh','relu'], 'solver' : ['adam','lbfgs']}\n",
    " \n",
    "# model\n",
    "grid_clf_acc3 = GridSearchCV(clf3, param_grid = param)\n",
    " \n",
    "# train the model\n",
    "grid_clf_acc3.fit(X_train_scaled, y_train)\n",
    " \n",
    "print('Grid best parameter (max. accuracy): ', grid_clf_acc3.best_params_)\n",
    "print('Grid best score (accuracy): ', grid_clf_acc3.best_score_)\n",
    " \n",
    "# alternative metric to optimize over grid parameters: AUC\n",
    "grid_clf_auc3 = GridSearchCV(clf3, param_grid = param, scoring = 'roc_auc')\n",
    "grid_clf_auc3.fit(X_train_scaled, y_train)\n",
    "predict_proba = grid_clf_auc3.predict_proba(X_test_scaled)[:,1]\n",
    " \n",
    "print('Test set AUC: ', roc_auc_score(y_test, predict_proba))\n",
    "print('Grid best parameter (max. AUC): ', grid_clf_auc3.best_params_)\n",
    "print('Grid best score (AUC): ', grid_clf_auc3.best_score_)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed225720166559e7176d3793db16a2fd8d295f725007103b21ac3099d2a89ee8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
