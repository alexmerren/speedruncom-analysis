{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Systems for Speedrun.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from operator import itemgetter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prefs_filename = \"../data/users/user_preferences_with_metadata.csv\"\n",
    "user_prefs_df = pd.read_csv(user_prefs_filename)\n",
    "user_prefs_df = user_prefs_df[(user_prefs_df['signup_date'].notna()) & (user_prefs_df['signup_date'] != \"Null\")]\n",
    "user_prefs_df['signup_date'] = pd.to_datetime(user_prefs_df['signup_date'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "user_prefs_df['signup_date'] = pd.to_datetime(user_prefs_df['signup_date'].dt.strftime('%Y-%m-%d'))\n",
    "user_prefs_df = user_prefs_df[(user_prefs_df['signup_date'] < '2023-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>signup_date</th>\n",
       "      <th>location</th>\n",
       "      <th>num_games</th>\n",
       "      <th>games</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>335322</td>\n",
       "      <td>335322</td>\n",
       "      <td>335322</td>\n",
       "      <td>335322.000000</td>\n",
       "      <td>335322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>335322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>j5wzz2qj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>k6q4rqzd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-28 13:40:53.271780608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.994465</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-01-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-09-16 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-25 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2059.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.410692</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user                    signup_date location      num_games  \\\n",
       "count     335322                         335322   335322  335322.000000   \n",
       "unique    335322                            NaN      257            NaN   \n",
       "top     j5wzz2qj                            NaN       us            NaN   \n",
       "freq           1                            NaN   101439            NaN   \n",
       "mean         NaN  2020-06-28 13:40:53.271780608      NaN       1.994465   \n",
       "min          NaN            2014-01-06 00:00:00      NaN       1.000000   \n",
       "25%          NaN            2019-09-16 00:00:00      NaN       1.000000   \n",
       "50%          NaN            2021-01-04 00:00:00      NaN       1.000000   \n",
       "75%          NaN            2021-09-25 00:00:00      NaN       2.000000   \n",
       "max          NaN            2022-12-31 00:00:00      NaN    2059.000000   \n",
       "std          NaN                            NaN      NaN       7.410692   \n",
       "\n",
       "           games  \n",
       "count     335322  \n",
       "unique     88806  \n",
       "top     k6q4rqzd  \n",
       "freq        5131  \n",
       "mean         NaN  \n",
       "min          NaN  \n",
       "25%          NaN  \n",
       "50%          NaN  \n",
       "75%          NaN  \n",
       "max          NaN  \n",
       "std          NaN  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prefs_df.describe(include='all', datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_games_df = user_prefs_df.copy()\n",
    "exploded_games_df['games'] = exploded_games_df['games'].str.split(',')\n",
    "exploded_games_df = exploded_games_df.explode('games').rename(columns = {'games': 'game_id', 'user':'user_id'})[['user_id', 'game_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>game_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>668788</td>\n",
       "      <td>668788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>335322</td>\n",
       "      <td>31425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>kj9521v8</td>\n",
       "      <td>k6q4rqzd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2059</td>\n",
       "      <td>6979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id   game_id\n",
       "count     668788    668788\n",
       "unique    335322     31425\n",
       "top     kj9521v8  k6q4rqzd\n",
       "freq        2059      6979"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploded_games_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bipartite_graph = nx.Graph()\n",
    "\n",
    "# Users have a bipartite value of 0, games have a bipartite value of 1.\n",
    "bipartite_graph.add_nodes_from(set(exploded_games_df['user_id'].values), bipartite=0)\n",
    "bipartite_graph.add_nodes_from(set(exploded_games_df['game_id'].values), bipartite=1)\n",
    "bipartite_graph.add_edges_from([(user, game) for user, game in zip(exploded_games_df['user_id'], exploded_games_df['game_id'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_bipartite(bipartite_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "del user_prefs_filename, user_prefs_df, exploded_games_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlapping Set Similarity with Limiting the Graph\n",
    "\n",
    "There are two methods of limiting the number of user-item interactions in our bipartite graph. We can either use the mean and standard deviation of the `num_games` column, or limit based on the integer number of games played by a given user. For example, we can either use three standard deviations of the mean to have a cutoff value of `24.2 (3 s.f.)`, or we can use the value of `2` for users that have played only one game.\n",
    "\n",
    "Using the method of standard deviations, we get a very similar output to the unlimited user-item interaction bipartite graph. We get popular games recommended most of the time. If we use the second approach, we get (anecdotally) more precise recommendations. However, the second method does not scale well, since we need to construct a different graph for each number of games played by each user. In reality, this isn't as bad as we think. Out of the 335,322 total users in our sample we can cover 306,371 users, or 91.4% (3 s.f.) of them with three graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_user_preferences_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df[(df['signup_date'].notna()) & (df['signup_date'] != \"Null\")]\n",
    "    df['signup_date'] = pd.to_datetime(df['signup_date'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "    df['signup_date'] = pd.to_datetime(df['signup_date'].dt.strftime('%Y-%m-%d'))\n",
    "    df = df[(df['signup_date'] < '2023-01-01')]\n",
    "    return df\n",
    "\n",
    "def limit_number_games_user_preferences_df(df: pd.DataFrame, num_games: int) -> pd.DataFrame:\n",
    "    return df[(df['num_games'] <= num_games)]\n",
    "\n",
    "def explode_games_played(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['games'] = df['games'].str.split(',')\n",
    "    return df.explode('games').rename(columns = {'games': 'game_id', 'user':'user_id'})\n",
    "\n",
    "def recommendation_graph_for_n_games_played(df: pd.DataFrame, n: int) -> tuple[pd.DataFrame, nx.Graph]:\n",
    "    df = clean_user_preferences_df(df)\n",
    "    df = limit_number_games_user_preferences_df(df, n+1)\n",
    "    df = explode_games_played(df)\n",
    "    bipartite_graph = nx.Graph()\n",
    "    bipartite_graph.add_nodes_from(set(df['user_id'].values), bipartite=0)\n",
    "    bipartite_graph.add_nodes_from(set(df['game_id'].values), bipartite=1)\n",
    "    bipartite_graph.add_edges_from([(user, game) for user, game in zip(df['user_id'], df['game_id'])])\n",
    "    return df, bipartite_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fp/pwtrzcy130zdfcx62mp9_kmc0000gn/T/ipykernel_2763/4036755379.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['signup_date'] = pd.to_datetime(df['signup_date'], format='%Y-%m-%dT%H:%M:%SZ')\n",
      "/var/folders/fp/pwtrzcy130zdfcx62mp9_kmc0000gn/T/ipykernel_2763/4036755379.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['signup_date'] = pd.to_datetime(df['signup_date'].dt.strftime('%Y-%m-%d'))\n"
     ]
    }
   ],
   "source": [
    "user_prefs_df = pd.read_csv('../data/users/user_preferences_with_metadata.csv')\n",
    "user_prefs_df, bipartite_graph = recommendation_graph_for_n_games_played(user_prefs_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_similarity(bipartite_graph: nx.Graph, total_item_nodes: int, user_a_id: str, user_b_id: str) -> float:\n",
    "    assert bipartite_graph.nodes[user_a_id]['bipartite'] == 0\n",
    "    assert bipartite_graph.nodes[user_b_id]['bipartite'] == 0\n",
    "\n",
    "    a_neighbours = bipartite_graph.neighbors(user_a_id)\n",
    "    b_neighbours = bipartite_graph.neighbors(user_b_id)\n",
    "    shared_nodes = set(a_neighbours).intersection(b_neighbours)\n",
    "\n",
    "    return len(shared_nodes) / total_item_nodes\n",
    "\n",
    "def most_similar_users(bipartite_graph: nx.Graph, user_id: str) -> tuple[list[str], float]:\n",
    "    all_users = set([user for user, value in bipartite_graph.nodes(data=True) if value['bipartite'] == 0])\n",
    "    all_users.remove(user_id)\n",
    "\n",
    "    total_item_nodes = 0\n",
    "    for _, values in bipartite_graph.nodes(data=True):\n",
    "        if values['bipartite'] == 1: total_item_nodes += 1\n",
    "\n",
    "    similarities = defaultdict(float)\n",
    "    for user in all_users:\n",
    "        similarities[user] = user_similarity(bipartite_graph, total_item_nodes, user_id, user)\n",
    "\n",
    "    max_similarity = max(similarities.values())\n",
    "    return [user for user, similarity in similarities.items() if similarity == max_similarity], max_similarity\n",
    "\n",
    "def recommend_games(bipartite_graph: nx.Graph, user_id: str) -> list[str]:\n",
    "    similar_users, _ = most_similar_users(bipartite_graph, user_id)\n",
    "    other_games = [game for user in similar_users for game in bipartite_graph.neighbors(user)]\n",
    "    game_rankings = Counter(other_games)\n",
    "\n",
    "    already_played_games = set(bipartite_graph.neighbors(user_id))\n",
    "\n",
    "    try:\n",
    "        [game_rankings.pop(game) for game in already_played_games]\n",
    "    except KeyError:\n",
    "        # If no other users in data set have played this game.\n",
    "        pass\n",
    "\n",
    "    ranked_games_in_order, _ = list(zip(*sorted(game_rankings.items(), key=itemgetter(1), reverse=True)))\n",
    "    \n",
    "    return ranked_games_in_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_metadata_df = pd.read_csv('../data/games/metadata/all_games.csv').rename(columns={'game_id': 'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Played games: ['Hello Neighbor' 'Super Mario Odyssey']\n",
      "Recommended games: [\"Baldi's Basics Category Extensions\" 'Google Quick Draw'\n",
      " 'Snipperclips: Cut it out  together!' 'Hello Neighbor 2' 'Cuphead'\n",
      " 'Super Mario Sunshine' 'Marble Saga: Kororinpa'\n",
      " 'The Legend of Zelda: The Wind Waker HD' 'Clicker Heroes'\n",
      " 'Minecraft: Java Edition' 'Island Saver'\n",
      " 'Super Mario Odyssey Category Extensions']\n"
     ]
    }
   ],
   "source": [
    "user = \"x355n6qj\"\n",
    "\n",
    "played_games = list(bipartite_graph.neighbors(user))\n",
    "print(f\"Played games: {games_metadata_df[(games_metadata_df['id'].isin(played_games))].game_name.values}\")\n",
    "\n",
    "recommended_games = recommend_games(bipartite_graph, user)\n",
    "print(f\"Recommended games: {games_metadata_df.set_index('id').loc(axis=0)[recommended_games].game_name.values[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "del games_metadata_df, played_games, recommended_games, user_prefs_df, bipartite_graph, user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Using a Game Similarity Matrix\n",
    "\n",
    "This recommendation method works by creating a matrix of how users have rated different games. We construct this matrix by rating a game `1` if a user has played it, and `0` if not. We then normalise these values by making the sum of ratings by each user equal to `1`. This is also called [scaling to a unit length](https://en.wikipedia.org/wiki/Feature_scaling#Scaling_to_unit_length). We take the dot product of the matrix and the transposed matrix, and this gives us the similarity between each item in the data set. The method is taken from [here](https://towardsdatascience.com/recommender-systems-item-customer-collaborative-filtering-ff0c8f41ae8a). **This method does not scale very well**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_user_prefs_df_to_ratings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    tmp_df = df.copy()\n",
    "    tmp_df['games'] = tmp_df['games'].str.split(',')\n",
    "    tmp_df = tmp_df.explode('games').rename(columns = {'games': 'game_id', 'user':'user_id'})\n",
    "    tmp_df['rating'] = 1\n",
    "    return tmp_df[['user_id', 'game_id', 'rating']]\n",
    "\n",
    "def construct_similarity_matrix(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    tmp_df = df.copy()\n",
    "    tmp_df = pd.pivot_table(tmp_df, values='rating', index='user_id', columns='game_id')\n",
    "    tmp_df = tmp_df.fillna(0.0)\n",
    "    normalised_tmp_df = tmp_df / np.sqrt(np.square(tmp_df).sum(axis=0))\n",
    "    return normalised_tmp_df.transpose().dot(normalised_tmp_df)\n",
    "\n",
    "def recommend_from_game(similarity_matrix: pd.DataFrame, game_id: str, n_recommendations: int) -> list[str]:\n",
    "    return similarity_matrix.nlargest(n_recommendations+1, game_id).index.values[1:]\n",
    "\n",
    "def recommendation_metrics_at_k(test_df: pd.DataFrame, similarity_matrix: pd.DataFrame, k: int) -> tuple[float, float, float]:\n",
    "    recommendations = []\n",
    "    unique_games_in_test = np.unique(test_df['games'].str.split(',').apply(pd.Series).stack().reset_index(drop=True))\n",
    "    for game in unique_games_in_test:\n",
    "        try:\n",
    "            game_row = similarity_matrix.loc[game]\n",
    "            recs = pd.Series(game_row).where(lambda x: x >= 0.1).dropna().sort_values(ascending=False).index.values.tolist()[1:k+1]\n",
    "            recommendations.extend(recs)\n",
    "        except KeyError:\n",
    "            # If no other users in data set have played this game.\n",
    "            pass\n",
    "\n",
    "    relevant_games_set = set(unique_games_in_test)\n",
    "    recommended_games_set = set(recommendations)\n",
    "    intersection = len(recommended_games_set.intersection(relevant_games_set))\n",
    "    recall = intersection/len(relevant_games_set)\n",
    "    precision = intersection/len(recommended_games_set)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return recall, precision, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_prefs_df = pd.read_csv('../data/users/user_preferences_with_metadata.csv').sample(10000, random_state=0)\n",
    "user_prefs_df = pd.read_csv('../data/users/user_preferences_with_metadata.csv').sort_values(by='num_games', ascending=False)[:2000]\n",
    "\n",
    "train_df, test_df = train_test_split(user_prefs_df, test_size=0.2, random_state=0)\n",
    "\n",
    "train_df = format_user_prefs_df_to_ratings(train_df)\n",
    "similarity_matrix = construct_similarity_matrix(train_df)\n",
    "# similarity_matrix = pd.read_csv('../data/too_big/game_similarity_matrix.csv').set_index('game_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.271015</td>\n",
       "      <td>0.540530</td>\n",
       "      <td>0.361019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.410347</td>\n",
       "      <td>0.502577</td>\n",
       "      <td>0.451803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.490772</td>\n",
       "      <td>0.475978</td>\n",
       "      <td>0.483262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.544611</td>\n",
       "      <td>0.460686</td>\n",
       "      <td>0.499145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.585636</td>\n",
       "      <td>0.453126</td>\n",
       "      <td>0.510929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.615186</td>\n",
       "      <td>0.446798</td>\n",
       "      <td>0.517642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.641102</td>\n",
       "      <td>0.442100</td>\n",
       "      <td>0.523321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.661949</td>\n",
       "      <td>0.439576</td>\n",
       "      <td>0.528316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.681457</td>\n",
       "      <td>0.438253</td>\n",
       "      <td>0.533443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.697428</td>\n",
       "      <td>0.436628</td>\n",
       "      <td>0.537040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.713398</td>\n",
       "      <td>0.435468</td>\n",
       "      <td>0.540815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.726595</td>\n",
       "      <td>0.434345</td>\n",
       "      <td>0.543685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.739122</td>\n",
       "      <td>0.433799</td>\n",
       "      <td>0.546721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.749450</td>\n",
       "      <td>0.433199</td>\n",
       "      <td>0.549040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.758631</td>\n",
       "      <td>0.432481</td>\n",
       "      <td>0.550903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.765994</td>\n",
       "      <td>0.431876</td>\n",
       "      <td>0.552338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.772688</td>\n",
       "      <td>0.430773</td>\n",
       "      <td>0.553159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.779000</td>\n",
       "      <td>0.430390</td>\n",
       "      <td>0.554451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.784833</td>\n",
       "      <td>0.430272</td>\n",
       "      <td>0.555823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.790188</td>\n",
       "      <td>0.430387</td>\n",
       "      <td>0.557257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Recall  Precision  F1-Score\n",
       "1   0.271015   0.540530  0.361019\n",
       "2   0.410347   0.502577  0.451803\n",
       "3   0.490772   0.475978  0.483262\n",
       "4   0.544611   0.460686  0.499145\n",
       "5   0.585636   0.453126  0.510929\n",
       "6   0.615186   0.446798  0.517642\n",
       "7   0.641102   0.442100  0.523321\n",
       "8   0.661949   0.439576  0.528316\n",
       "9   0.681457   0.438253  0.533443\n",
       "10  0.697428   0.436628  0.537040\n",
       "11  0.713398   0.435468  0.540815\n",
       "12  0.726595   0.434345  0.543685\n",
       "13  0.739122   0.433799  0.546721\n",
       "14  0.749450   0.433199  0.549040\n",
       "15  0.758631   0.432481  0.550903\n",
       "16  0.765994   0.431876  0.552338\n",
       "17  0.772688   0.430773  0.553159\n",
       "18  0.779000   0.430390  0.554451\n",
       "19  0.784833   0.430272  0.555823\n",
       "20  0.790188   0.430387  0.557257"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns=['Recall', 'Precision', 'F1-Score'])\n",
    "for number_k in range(1, 21):\n",
    "    recall, precision, f1_score = recommendation_metrics_at_k(test_df, similarity_matrix, number_k)\n",
    "    results_df.loc[number_k] = recall, precision, f1_score\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('./random_users_2500_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_metadata_df = pd.read_csv('../data/games/metadata/all_games.csv').rename(columns={'game_id': 'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Played Game: ROBLOX: Obby King Remastered\n",
      "Recommended games: [\"Juke's Towers of Hell\" 'ROBLOX: box land'\n",
      " 'Adventure Forward 2: Category Extensions' 'Roblox: Teamwork Obby'\n",
      " 'ROBLOX: Lava Tumble'\n",
      " 'Minions Adventure Obby: Despicable Forces Category Extensions'\n",
      " 'Super Paper Roblox' 'Adventure Forward 2: Points of Conflict'\n",
      " 'ROBLOX: The NEAT Project' 'ROBLOX: Obby Island']\n"
     ]
    }
   ],
   "source": [
    "game_id = \"4d79j2g1\"\n",
    "n = 10\n",
    "recommended_games = recommend_from_game(similarity_matrix, game_id, n)\n",
    "\n",
    "print(f\"Played Game: {games_metadata_df.set_index('id').loc(axis=0)[game_id].game_name}\")\n",
    "print(f\"Recommended games: {games_metadata_df.set_index('id').loc(axis=0)[recommended_games].game_name.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del game_id, n, recommended_games, games_metadata_df, user_prefs_df, train_df, test_df, similarity_matrix, results_df, recall, precision, f1_score, number_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation using Node2Vec Embeddings\n",
    "\n",
    "The idea behind using node2vec embeddings for recommendation is to predict future links that don't already exist. We can prove that this works for individual games recommendation by removing selected edges and using cosine similarity of embeddings to predict which edges should exist given this graph. We carry this on further by creating a pipeline to predict games to play when they are completely disconnected.\n",
    "\n",
    "Do [this](https://sparsh-ai.github.io/rec-tutorials/graph%20embedding%20movielens%20factorization/2021/04/24/Recommendation-Node2vec.html)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, auc, roc_curve, roc_auc_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_existence_df = pd.read_csv('../data/games/network/edge_existence_dataset.csv').set_index('index')\n",
    "embeddings_df = pd.read_csv('../data/games/network/embeddings/test.emb', delimiter=\" \", skiprows=1, index_col=0, header=None).rename(columns={0: 'id'}).add_prefix(\"dim_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_features = [(embeddings_df.loc[node1].values.tolist()+embeddings_df.loc[node2].values.tolist()) for node1, node2 in zip(edge_existence_df[\"source\"], edge_existence_df[\"target\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(edge_features)\n",
    "y = edge_existence_df['connection']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10471, 32), (10471,))"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max. accuracy):  {'max_depth': 15, 'n_estimators': 50}\n",
      "Grid best score (accuracy):  0.9985675631933949\n",
      "Test set AUC:  0.999998330779426\n",
      "Grid best parameter (max. AUC):  {'max_depth': 10, 'n_estimators': 50}\n",
      "Grid best score (AUC):  0.9999765448696089\n"
     ]
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier()\n",
    " \n",
    "# parameters\n",
    "param = {'n_estimators' : [10,50,100], 'max_depth' : [5,10,15]}\n",
    " \n",
    "# model\n",
    "grid_clf_acc1 = GridSearchCV(clf1, param_grid = param)\n",
    " \n",
    "# train the model\n",
    "grid_clf_acc1.fit(X_train, y_train)\n",
    " \n",
    "print('Grid best parameter (max. accuracy): ', grid_clf_acc1.best_params_)\n",
    "print('Grid best score (accuracy): ', grid_clf_acc1.best_score_)\n",
    " \n",
    "# alternative metric to optimize over grid parameters: AUC\n",
    "grid_clf_auc1 = GridSearchCV(clf1, param_grid = param, scoring = 'roc_auc')\n",
    "grid_clf_auc1.fit(X_train, y_train)\n",
    "predict_proba = grid_clf_auc1.predict_proba(X_test)[:,1]\n",
    " \n",
    "print('Test set AUC: ', roc_auc_score(y_test, predict_proba))\n",
    "print('Grid best parameter (max. AUC): ', grid_clf_auc1.best_params_)\n",
    "print('Grid best score (AUC): ', grid_clf_auc1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 929,    0],\n",
       "       [  10, 2552]], dtype=int64)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(grid_clf_auc1.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if there is a link between super mario odyssey and super mario 64 (there is).\n",
    "# IDs: 76r55vd8 o1y9wo6q\n",
    "SMO = [0.003971752, 0.00646716, 0.005253054, 0.000770621, 0.023088027, -0.0025586337, 0.021919776, 0.023069408, 0.00055524334, 0.018905181, -0.015266668, -0.0029585548, 0.010636453, -0.017556641, -0.0020937473, -0.029378641, 0.013062697, -0.009451449, -0.020212192, 0.017371856, 0.003602054, -0.026192848, -0.025948, 0.017900482, 0.02082228, -0.019447599, 0.020568952, 0.025263663, -0.01999519, -0.023548912, -0.019287951, -0.011146348]\n",
    "SM64 = [-0.012588676, -0.029154047, -0.0028756857, -0.009487752, 0.017457027, 0.0210394, -0.010649294, -0.0018646903, 0.022166133, -0.024311021, 0.0062766, -0.029152796, -0.030749485, 0.0017411523, 0.029207725, -0.015724432, 0.009961858, 0.008669887, 0.01067755, -0.012766957, 0.0050436445, -0.0035253912, -0.008545488, -0.022413097, -0.014777329, -0.005886156, -0.024985388, 0.004289292, -0.0025947131, 0.0019044504, -0.014002968, -0.02486419]\n",
    "\n",
    "smo_sm64_features = np.array(SMO + SM64).reshape(1, -1)\n",
    "grid_clf_auc1.predict(smo_sm64_features)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed225720166559e7176d3793db16a2fd8d295f725007103b21ac3099d2a89ee8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
