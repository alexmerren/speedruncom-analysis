{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from networkx.algorithms import pagerank\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n",
    "We have defined `FINAL_DATE` to mark the cutoff date for the entire project, we use this for the filter on the network so any games that were released/created after the cutoff date are not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DATE = datetime(2023, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Generation\n",
    "\n",
    "We have three functions to generate directed graphs using the `networkx` package. At the moment, the function `generate_network_filter` removes entries in the collated related games file where the game has a release date or created date after the cutoff date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_network_filter(filename: str):\n",
    "    with open(filename, 'r') as openfile:\n",
    "        csv_reader = csv.reader(openfile)\n",
    "        next(csv_reader)\n",
    "        filter_map = defaultdict(bool)\n",
    "        for row in csv_reader:\n",
    "            # Check if the created/release date is after 2023, if it is then we can ignore it in the network.\n",
    "            release_date = datetime.strptime(row[3], \"%Y-%m-%d\")\n",
    "            if row[4] == \"None\":\n",
    "                row[4] = \"2017-10-22T05:21:29Z\" # This is a completely random date before the final date.\n",
    "            created_date = datetime.strptime(row[4], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            if created_date < FINAL_DATE and release_date < FINAL_DATE:\n",
    "                filter_map[row[0]] = True\n",
    "\n",
    "    return filter_map\n",
    "\n",
    "def get_weighted_edges_from_csv(filename, filter=None):\n",
    "    with open(filename, 'r') as openfile:\n",
    "        csv_reader = csv.reader(openfile)\n",
    "        next(csv_reader)\n",
    "\n",
    "        edges = list()\n",
    "        for row in csv_reader:\n",
    "            if filter is None:\n",
    "                edges.append(tuple([row[0], row[1], int(row[2])]))\n",
    "                continue\n",
    "            \n",
    "            if not filter.get(row[0]) or not filter.get(row[1]):\n",
    "                continue\n",
    "\n",
    "            edges.append(tuple([row[0], row[1], int(row[2])]))\n",
    "\n",
    "    return edges\n",
    "\n",
    "def generate_graph_from_edges(edges_list):\n",
    "    directed_graph = nx.DiGraph()\n",
    "    directed_graph.add_weighted_edges_from(edges_list)\n",
    "    return directed_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Functions\n",
    "\n",
    "Here are some functions that I am using to measure the network. Currently, we are measuring betweenness centrality, pagerank popularity, and probably some communities in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_n_pagerank_nodes(g: nx.Graph, n=1):\n",
    "    values = pagerank(g)\n",
    "    values_sorted = dict(sorted(values.items(), key=lambda item: item[1], reverse=True))\n",
    "    return list(values_sorted)[0:n]\n",
    "\n",
    "def get_graph_order_size(g: nx.Graph):\n",
    "    return g.order(), g.size()\n",
    "\n",
    "def find_top_n_betweenness_centrality_nodes(g: nx.Graph, n=10):\n",
    "    degree_centrality = nx.degree_centrality(g)\n",
    "    betweenness_centrality = nx.betweenness_centrality(g, normalized=True, endpoints=True)\n",
    "\n",
    "    degree_centrality_sorted = dict(sorted(degree_centrality.items(), key=lambda item: item[1], reverse=True))\n",
    "    betweenness_centrality_sorted = dict(sorted(betweenness_centrality.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    keys_top_degree = list(degree_centrality_sorted)[0:n]\n",
    "    keys_top_betweenness = list(betweenness_centrality_sorted)[0:n]\n",
    "    return list(set(keys_top_degree) & set(keys_top_betweenness))\n",
    "\n",
    "def find_degree_sequence(g: nx.Graph):\n",
    "    return [g.degree(n) for n in g.nodes]\n",
    "\n",
    "def find_top_n_highest_out_degree_node(g: nx.Graph, n=10):\n",
    "    return sorted(g.out_degree(), key=itemgetter(1), reverse=True)[:n]\n",
    "\n",
    "def find_top_n_highest_out_degree_with_weight(g: nx.Graph, n=10):\n",
    "    return sorted(g.out_degree(weight='weight'), key=itemgetter(1), reverse=True)[:n]\n",
    "\n",
    "def find_top_n_highest_in_degree_node(g: nx.Graph, n=10):\n",
    "    return sorted(g.in_degree(), key=itemgetter(1), reverse=True)[:n]\n",
    "\n",
    "def find_top_n_highest_in_degree_with_weight(g: nx.Graph, n=10):\n",
    "    return sorted(g.in_degree(weight='weight'), key=itemgetter(1), reverse=True)[:n]\n",
    "\n",
    "def is_graph_weakly_connected(g: nx.Graph):\n",
    "    return nx.is_weakly_connected(g)\n",
    "\n",
    "def find_number_weakly_connected_components(g: nx.Graph):\n",
    "    return nx.number_weakly_connected_components(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unlimited Related Games Network\n",
    "\n",
    "We are generating a network using the entire related games network that has been filtered using the previously mentioned function. This gives us a directed graph with **30,434 nodes**, and **14,744,682 edges**. Without filtering, we get a network that has **30,970 nodes** and **14,857,762 edges**. The filtering removes **536 edges** and **113,080 nodes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILTERED: (30434, 14744682)\n",
      "UNFILTERED: (30970, 14857762)\n"
     ]
    }
   ],
   "source": [
    "filter_filename = \"../data/games_information/all_games.csv\"\n",
    "graph_filename = \"../data/too_big/all_games.csv\"\n",
    "filter_map = generate_network_filter(filter_filename)\n",
    "edges = get_weighted_edges_from_csv(graph_filename, filter=filter_map)\n",
    "filtered_graph = generate_graph_from_edges(edges)\n",
    "print(f\"FILTERED: {get_graph_order_size(filtered_graph)}\")\n",
    "\n",
    "edges = get_weighted_edges_from_csv(graph_filename, filter=None)\n",
    "unfiltered_graph = generate_graph_from_edges(edges)\n",
    "print(f\"UNFILTERED: {get_graph_order_size(unfiltered_graph)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIGHEST OUT: [('k6q4rqzd', 9207), ('o1y9j9v6', 7492), ('o1y9wo6q', 7295), ('k6q474zd', 6851), ('om1m3625', 6795), ('46w0n91r', 6684), ('9d3rv59d', 6649), ('3dxz7p1y', 6295), ('pd0wq31e', 6289), ('76rmo418', 6002)]\n",
      "HIGHEST OUT WITH WEIGHT: [('k6q4rqzd', 151265), ('o1y9wo6q', 101525), ('k6q474zd', 90114), ('o1y9pyk6', 80738), ('o1yj5n21', 79965), ('j1n29w1p', 75480), ('369pxvg1', 73016), ('m1mnnojd', 69516), ('76r55vd8', 69313), ('kdknmqdm', 67746)]\n",
      "HIGHEST IN: [('k6q4rqzd', 9211), ('o1y9j9v6', 7488), ('o1y9wo6q', 7302), ('k6q474zd', 6855), ('om1m3625', 6795), ('46w0n91r', 6696), ('9d3rv59d', 6656), ('3dxz7p1y', 6299), ('pd0wq31e', 6293), ('76rmo418', 6004)]\n",
      "HIGHEST IN WITH WEIGHT: [('k6q4rqzd', 2005087), ('j1ne0vl1', 1643535), ('nd285r3d', 1093294), ('w6jl9o5d', 967633), ('3dx2j9y1', 840104), ('j1ll47v1', 758797), ('o1y7pv1q', 553313), ('m1zjnrm6', 551302), ('o1yj5n21', 521378), ('9dowpxm1', 487811)]\n"
     ]
    }
   ],
   "source": [
    "print(f\"HIGHEST OUT: {find_top_n_highest_out_degree_node(filtered_graph)}\")\n",
    "print(f\"HIGHEST OUT WITH WEIGHT: {find_top_n_highest_out_degree_with_weight(filtered_graph)}\")\n",
    "print(f\"HIGHEST IN: {find_top_n_highest_in_degree_node(filtered_graph)}\")\n",
    "print(f\"HIGHEST IN WITH WEIGHT: {find_top_n_highest_in_degree_with_weight(filtered_graph)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is not weakly connected. This means that we cannot reach every node in the graph by moving along edges -- there are some unconnected games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_graph_weakly_connected(filtered_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Percentage Limited Networks \n",
    "\n",
    "Using a limited version of the full network (10% representing the collated related games of the first 10% of games in the `data/related_games/` directory, ~3000 games.) we can see how the network evolves over time. We can see that there is a logarithmic increase in the number of nodes, or games, represented in the network when more time progresses.\n",
    "\n",
    "| Percentage | # Nodes | # Edges |\n",
    "|----|---|---|\n",
    "| 10 | 21713 | 1798823 | \n",
    "| 20 | 25919 | 3073789 | \n",
    "| 30 | 27426 | 4205049 | \n",
    "| 40 | 28594 | 5585984 | \n",
    "| 50 | 29345 | 7238562 | \n",
    "| 60 | 29776 | 9015808 | \n",
    "| 70 | 30088 | 10609558 | \n",
    "| 80 | 30292 | 12132973 | \n",
    "| 90 | 30398 | 13535490 | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10: (27244, 1445265)\n",
      "20: (28920, 2892985)\n",
      "30: (29577, 4376975)\n",
      "40: (29930, 5801217)\n",
      "50: (30144, 7251401)\n",
      "60: (30274, 8707409)\n",
      "70: (30349, 10247364)\n",
      "80: (30398, 11800570)\n",
      "90: (30427, 13290703)\n"
     ]
    }
   ],
   "source": [
    "filter_filename = \"../data/games_information/all_games.csv\"\n",
    "filter_map = generate_network_filter(filter_filename)\n",
    "\n",
    "percentages_files = {\n",
    "    \"10\":\"../data/too_big/all_games_10_percent.csv\",\n",
    "    \"20\":\"../data/too_big/all_games_20_percent.csv\",\n",
    "    \"30\":\"../data/too_big/all_games_30_percent.csv\",\n",
    "    \"40\":\"../data/too_big/all_games_40_percent.csv\",\n",
    "    \"50\":\"../data/too_big/all_games_50_percent.csv\",\n",
    "    \"60\":\"../data/too_big/all_games_60_percent.csv\",\n",
    "    \"70\":\"../data/too_big/all_games_70_percent.csv\",\n",
    "    \"80\":\"../data/too_big/all_games_80_percent.csv\",\n",
    "    \"90\":\"../data/too_big/all_games_90_percent.csv\",\n",
    "}\n",
    "\n",
    "for percentage, filename in percentages_files.items():\n",
    "    edges = get_weighted_edges_from_csv(filename, filter=filter_map)\n",
    "    graph = generate_graph_from_edges(edges)\n",
    "    print(f\"{percentage}: {get_graph_order_size(graph)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the top 21 betweenness centrality nodes, which can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21713, 1798823)\n",
      "['k6qew96g', 'y65457de', 'm1mp9312', '76rmo418', '4d7eog67', 'w6jkle1j', 'kdkz7ldm', '9doye36p', 'kdkzvmld', '9d3rr0dl', 'kyd4gde4', 'l3dx51yv', 'y658506e', 'v1p0x468', 'm9do0odp', 'pd0wq31e', 'om1m3625', '46w2l76r', 'nd28gvd0', '3dxzqv1y', '369go31l']\n"
     ]
    }
   ],
   "source": [
    "filter_filename = \"../data/games_information/all_games.csv\"\n",
    "graph_filename = \"../data/too_big/all_games_10_percent.csv\"\n",
    "filter_map = generate_network_filter(filter_filename)\n",
    "edges = get_weighted_edges_from_csv(graph_filename, filter=filter_map)\n",
    "graph = generate_graph_from_edges(edges)\n",
    "print(get_graph_order_size(graph))\n",
    "\n",
    "highest_bc_nodes = find_top_n_betweenness_centrality_nodes(graph, n=25)\n",
    "print(highest_bc_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to visualise the 10% graph, it's very slow and annoying to do :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.circular(graph)\n",
    "nx.draw_networkx(\n",
    "    graph,\n",
    "    pos=pos,\n",
    "    node_size=0,\n",
    "    edge_color=\"#444444\",\n",
    "    alpha=0.05,\n",
    "    with_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(graph, k=0.1)\n",
    "nx.draw_networkx(\n",
    "    graph,\n",
    "    pos=pos,\n",
    "    node_size=0,\n",
    "    edge_color=\"#444444\",\n",
    "    alpha=0.05,\n",
    "    with_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying `graph-tool` for Fast Network Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graph_tool'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\ajcm203\\speedruncom-data\\analysis\\Network_Analysis.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ajcm203/speedruncom-data/analysis/Network_Analysis.ipynb#ch0000019?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgraph_tool\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mall\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'graph_tool'"
     ]
    }
   ],
   "source": [
    "from graph_tool.all import *\n",
    "# https://git.skewed.de/count0/graph-tool/-/wikis/installation-instructions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aeeec63d06273d17ce9164221d232af429b3d076ba4020c4f87a9782ce9b50a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
