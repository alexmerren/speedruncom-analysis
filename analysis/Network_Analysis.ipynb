{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import networkx as nx\n",
    "from networkx.algorithms import pagerank\n",
    "from collections import defaultdict\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n",
    "We have defined `FINAL_DATE` to mark the cutoff date for the entire project, we use this for the filter on the network so any games that were released/created after the cutoff date are not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DATE = datetime(2023, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Generation\n",
    "\n",
    "We have three functions to generate directed graphs using the `networkx` package. At the moment, the function `generate_network_filter` removes entries in the collated related games file where the game has a release date or created date after the cutoff date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_network_filter(filename: str):\n",
    "    with open(filename, 'r') as openfile:\n",
    "        csv_reader = csv.reader(openfile)\n",
    "        next(csv_reader)\n",
    "        filter_map = defaultdict(bool)\n",
    "        for row in csv_reader:\n",
    "            # Check if the created/release date is after 2023, if it is then we can ignore it in the network.\n",
    "            release_date = datetime.strptime(row[3], \"%Y-%m-%d\")\n",
    "            if row[4] == \"None\":\n",
    "                row[4] = \"2017-10-22T05:21:29Z\"\n",
    "            created_date = datetime.strptime(row[4], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            if created_date < FINAL_DATE and release_date < FINAL_DATE:\n",
    "                filter_map[row[0]] = True\n",
    "\n",
    "    return filter_map\n",
    "\n",
    "def get_weighted_edges_from_csv(filename, filter=None):\n",
    "    with open(filename, 'r') as openfile:\n",
    "        csv_reader = csv.reader(openfile)\n",
    "        next(csv_reader)\n",
    "\n",
    "        edges = list()\n",
    "        for row in csv_reader:\n",
    "            if filter is None:\n",
    "                edges.append(tuple([row[0], row[1], int(row[2])]))\n",
    "                continue\n",
    "            \n",
    "            if not filter.get(row[0]) or not filter.get(row[1]):\n",
    "                continue\n",
    "\n",
    "            edges.append(tuple([row[0], row[1], int(row[2])]))\n",
    "\n",
    "    return edges\n",
    "\n",
    "def generate_graph_from_edges(edges_list):\n",
    "    directed_graph = nx.DiGraph()\n",
    "    directed_graph.add_weighted_edges_from(edges_list)\n",
    "    return directed_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Functions\n",
    "\n",
    "Here are some functions that I am using to measure the network. Currently, we are measuring betweenness centrality, pagerank popularity, and probably some communities in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_n_pagerank_nodes(g: nx.Graph, n=1):\n",
    "    values = pagerank(g)\n",
    "    values_sorted = dict(sorted(values.items(), key=lambda item: item[1], reverse=True))\n",
    "    return list(values_sorted)[0:n]\n",
    "\n",
    "def get_graph_order_size(g: nx.Graph):\n",
    "    return g.order(), g.size()\n",
    "\n",
    "def find_top_n_betweenness_centrality_nodes(g: nx.Graph, n=10):\n",
    "    degree_centrality = nx.degree_centrality(g)\n",
    "    betweenness_centrality = nx.betweenness_centrality(g, normalized=True, endpoints=True)\n",
    "\n",
    "    degree_centrality_sorted = dict(sorted(degree_centrality.items(), key=lambda item: item[1], reverse=True))\n",
    "    betweenness_centrality_sorted = dict(sorted(betweenness_centrality.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    keys_top_degree = list(degree_centrality_sorted)[0:n]\n",
    "    keys_top_betweenness = list(betweenness_centrality_sorted)[0:n]\n",
    "    return list(set(keys_top_degree) & set(keys_top_betweenness))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unlimited Related Games Network\n",
    "\n",
    "We are generating a network using the entire related games network that has been filtered using the previously mentioned function. This gives us a directed graph with **30,434 nodes**, and **14,744,682 edges**. Without filtering, we get a network that has **30,970 nodes** and **14,857,762 edges**. The filtering removes **536 edges** and **113,080 nodes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILTERED: (30434, 14744682)\n",
      "UNFILTERED: (30970, 14857762)\n"
     ]
    }
   ],
   "source": [
    "filter_filename = \"../data/games_information/all_games.csv\"\n",
    "graph_filename = \"../data/too_big/all_games.csv\"\n",
    "filter_map = generate_network_filter(filter_filename)\n",
    "edges = get_weighted_edges_from_csv(graph_filename, filter=filter_map)\n",
    "graph = generate_graph_from_edges(edges)\n",
    "print(f\"FILTERED: {get_graph_order_size(graph)}\")\n",
    "\n",
    "edges = get_weighted_edges_from_csv(graph_filename, filter=None)\n",
    "graph = generate_graph_from_edges(edges)\n",
    "print(f\"UNFILTERED: {get_graph_order_size(graph)}\")\n",
    "# print(find_top_n_betweenness_centrality_nodes(graph, n=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_filename = \"../data/games_information/all_games.csv\"\n",
    "graph_filename = \"../data/too_big/all_games.csv\"\n",
    "filter_map = generate_network_filter(filter_filename)\n",
    "edges = get_weighted_edges_from_csv(graph_filename, filter=filter_map)\n",
    "graph = generate_graph_from_edges(edges)\n",
    "highest_bc_nodes = find_top_n_betweenness_centrality_nodes(graph, n=25)\n",
    "print(highest_bc_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Percentage Limited Networks \n",
    "\n",
    "Using a limited version of the full network (10% representing the collated related games of the first 10% of games in the `data/related_games/` directory, ~3000 games.) we can see how the network evolves over time. We can see that there is a logarithmic increase in the number of nodes, or games, represented in the network when more time progresses.\n",
    "\n",
    "| Percentage | # Nodes | # Edges |\n",
    "|----|---|---|\n",
    "| 10 | 21713 | 1798823 | \n",
    "| 20 | 25919 | 3073789 | \n",
    "| 30 | 27426 | 4205049 | \n",
    "| 40 | 28594 | 5585984 | \n",
    "| 50 | 29345 | 7238562 | \n",
    "| 60 | 29776 | 9015808 | \n",
    "| 70 | 30088 | 10609558 | \n",
    "| 80 | 30292 | 12132973 | \n",
    "| 90 | 30398 | 13535490 | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10: (21713, 1798823)\n",
      "20: (25919, 3073789)\n",
      "30: (27426, 4205049)\n",
      "40: (28594, 5585984)\n",
      "50: (29345, 7238562)\n",
      "60: (29776, 9015808)\n",
      "70: (30088, 10609558)\n",
      "80: (30292, 12132973)\n",
      "90: (30398, 13535490)\n"
     ]
    }
   ],
   "source": [
    "filter_filename = \"../data/games_information/all_games.csv\"\n",
    "filter_map = generate_network_filter(filter_filename)\n",
    "\n",
    "percentages_files = {\n",
    "    \"10\":\"../data/too_big/all_games_10_percent.csv\",\n",
    "    \"20\":\"../data/too_big/all_games_20_percent.csv\",\n",
    "    \"30\":\"../data/too_big/all_games_30_percent.csv\",\n",
    "    \"40\":\"../data/too_big/all_games_40_percent.csv\",\n",
    "    \"50\":\"../data/too_big/all_games_50_percent.csv\",\n",
    "    \"60\":\"../data/too_big/all_games_60_percent.csv\",\n",
    "    \"70\":\"../data/too_big/all_games_70_percent.csv\",\n",
    "    \"80\":\"../data/too_big/all_games_80_percent.csv\",\n",
    "    \"90\":\"../data/too_big/all_games_90_percent.csv\",\n",
    "}\n",
    "\n",
    "for percentage, filename in percentages_files.items():\n",
    "    edges = get_weighted_edges_from_csv(filename, filter=filter_map)\n",
    "    graph = generate_graph_from_edges(edges)\n",
    "    print(f\"{percentage}: {get_graph_order_size(graph)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21713, 1798823)\n",
      "['k6qew96g', 'y65457de', 'm1mp9312', '76rmo418', '4d7eog67', 'w6jkle1j', 'kdkz7ldm', '9doye36p', 'kdkzvmld', '9d3rr0dl', 'kyd4gde4', 'l3dx51yv', 'y658506e', 'v1p0x468', 'm9do0odp', 'pd0wq31e', 'om1m3625', '46w2l76r', 'nd28gvd0', '3dxzqv1y', '369go31l']\n"
     ]
    }
   ],
   "source": [
    "filter_filename = \"../data/games_information/all_games.csv\"\n",
    "graph_filename = \"../data/too_big/all_games_10_percent.csv\"\n",
    "filter_map = generate_network_filter(filter_filename)\n",
    "edges = get_weighted_edges_from_csv(graph_filename, filter=filter_map)\n",
    "graph = generate_graph_from_edges(edges)\n",
    "print(get_graph_order_size(graph))\n",
    "\n",
    "highest_bc_nodes = find_top_n_betweenness_centrality_nodes(graph, n=25)\n",
    "print(highest_bc_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.circular(graph)\n",
    "nx.draw_networkx(\n",
    "    graph,\n",
    "    pos=pos,\n",
    "    node_size=0,\n",
    "    edge_color=\"#444444\",\n",
    "    alpha=0.05,\n",
    "    with_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(graph, k=0.1)\n",
    "nx.draw_networkx(\n",
    "    graph,\n",
    "    pos=pos,\n",
    "    node_size=0,\n",
    "    edge_color=\"#444444\",\n",
    "    alpha=0.05,\n",
    "    with_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying `graph-tool` for Fast Network Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graph_tool'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\ajcm203\\speedruncom-data\\analysis\\Network_Analysis.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ajcm203/speedruncom-data/analysis/Network_Analysis.ipynb#ch0000019?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgraph_tool\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mall\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'graph_tool'"
     ]
    }
   ],
   "source": [
    "from graph_tool.all import *\n",
    "# https://git.skewed.de/count0/graph-tool/-/wikis/installation-instructions"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed225720166559e7176d3793db16a2fd8d295f725007103b21ac3099d2a89ee8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
